{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d7763caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "109553ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "ucirepo_ids = {\n",
    "    \"iris\": 53,\n",
    "    \"heart_disease\": 45,\n",
    "    \"molecular_biology\": 69,\n",
    "    \"breast_cancer\": 17,\n",
    "    \"adult\": 2,\n",
    "    \"bank_marketing\": 222,\n",
    "    \"student_performance\": 320,\n",
    "    \"wine\": 109,\n",
    "    \"mushroom\": 73\n",
    "}\n",
    "\n",
    "DATASET_NAME = \"mushroom\"  # Example dataset name\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def custom_data():\n",
    "    \n",
    "    data = {\n",
    "            'age': ['youth', 'youth', 'middle aged', 'senior', 'senior', 'senior', 'middle aged',\n",
    "                    'youth', 'youth', 'senior', 'youth', 'middle aged', 'middle aged', 'senior'],\n",
    "            'income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low',\n",
    "                    'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "            'student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes',\n",
    "                        'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no'],\n",
    "            'credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent',\n",
    "                            'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent'],\n",
    "            'buys_computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes',\n",
    "                            'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "        }\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Split into features and target\n",
    "    features = df.drop(columns='buys_computer')\n",
    "    targets = df['buys_computer']\n",
    "    targets= pd.DataFrame(targets.values.reshape(-1, 1), columns=['buys_computer'])\n",
    "\n",
    "    \n",
    "    # Variable info\n",
    "    variable_info = {\n",
    "        col: {\n",
    "            'type': 'categorical',\n",
    "            'unique_values': df[col].unique().tolist()\n",
    "        } for col in df.columns\n",
    "    }\n",
    "\n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        'source': 'Simulated AllElectronics dataset',\n",
    "        'description': 'Customer attributes and their decision to buy a computer',\n",
    "        'num_samples': len(df),\n",
    "        'num_features': features.shape[1],\n",
    "        'target_column': 'buys_computer',\n",
    "        'class_labels': sorted(df['buys_computer'].unique().tolist())\n",
    "    }\n",
    "\n",
    "    # Build nested structure\n",
    "    return SimpleNamespace(\n",
    "        data=SimpleNamespace(\n",
    "            features=features,\n",
    "            targets=targets,\n",
    "            feature_names=features.columns.tolist(),\n",
    "            target_names=sorted(targets.iloc[:,0].unique()),\n",
    "            # frame=df\n",
    "        ),\n",
    "        metadata=metadata,\n",
    "        variables=variable_info\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "def fetch_dataframe(dataframe_name):\n",
    "    \n",
    "    if dataframe_name == \"custom_data\":\n",
    "        df = custom_data()\n",
    "        \n",
    "        # metadata \n",
    "        print(df.metadata) \n",
    "        \n",
    "        # variable information \n",
    "        print(df.variables) \n",
    "    \n",
    "        return df\n",
    "    \n",
    "    if dataframe_name in ucirepo_ids:\n",
    "        # fetch dataset \n",
    "        df = fetch_ucirepo(id=ucirepo_ids[dataframe_name],) \n",
    "\n",
    "        # # data (as pandas dataframes) \n",
    "        X = df.data.features \n",
    "        y = df.data.targets \n",
    "        \n",
    "        # metadata \n",
    "        print(df.metadata) \n",
    "        \n",
    "        # variable information \n",
    "        print(df.variables) \n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset '{dataframe_name}' not found in UCI repository.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "95af5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __train_test_split(X, y, test_size = 0.2, shuffle_and_stratify = True):\n",
    "    \n",
    "    if test_size < 0 or test_size > 1:\n",
    "        raise ValueError(\"test_size must be between 0 and 1\")\n",
    "   \n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"Features and targets must have the same length.\")\n",
    "\n",
    "    \n",
    "    if shuffle_and_stratify == False:\n",
    "    \n",
    "        train_size = 1 - test_size\n",
    "        train_index = int(len(X) * train_size)\n",
    "        \n",
    "        X_train = X[0: train_index]\n",
    "        X_test = X[train_index:]\n",
    "        \n",
    "        y_train = y[0: train_index]\n",
    "        y_test = y[train_index:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        labels = y.iloc[:,0].unique()\n",
    "        X_train = pd.DataFrame(columns=X.columns)\n",
    "        y_train = pd.DataFrame(columns=y.columns)\n",
    "        X_test = pd.DataFrame(columns=X.columns)\n",
    "        y_test = pd.DataFrame(columns=y.columns)\n",
    "        \n",
    "        train_size = 1 - test_size\n",
    "        \n",
    "\n",
    "        for label in labels :\n",
    "            y_rows = y[y.iloc[:,0] == label]            \n",
    "            X_rows = X.loc[y_rows.index]\n",
    "            \n",
    "            train_index = int(len(X_rows) * train_size)\n",
    "            \n",
    "            X_train = pd.concat([X_train, X_rows.iloc[:train_index]], ignore_index=False)\n",
    "            y_train = pd.concat([y_train, y_rows.iloc[:train_index]] , ignore_index=False)\n",
    "            \n",
    "            X_test = pd.concat([X_test, X_rows[train_index:]], ignore_index=False)\n",
    "            y_test = pd.concat([y_test, y_rows[train_index:]], ignore_index=False)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "3563c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 73, 'name': 'Mushroom', 'repository_url': 'https://archive.ics.uci.edu/dataset/73/mushroom', 'data_url': 'https://archive.ics.uci.edu/static/public/73/data.csv', 'abstract': 'From Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edible', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 8124, 'num_features': 22, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['poisonous'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1981, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5959T', 'creators': [], 'intro_paper': None, 'additional_info': {'summary': \"This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '     1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\\r\\n     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\\r\\n     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\\r\\n     4. bruises?:                 bruises=t,no=f\\r\\n     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\\r\\n     6. gill-attachment:          attached=a,descending=d,free=f,notched=n\\r\\n     7. gill-spacing:             close=c,crowded=w,distant=d\\r\\n     8. gill-size:                broad=b,narrow=n\\r\\n     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\\r\\n    10. stalk-shape:              enlarging=e,tapering=t\\r\\n    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\\r\\n    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\\r\\n    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\\r\\n    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\\r\\n    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\\r\\n    16. veil-type:                partial=p,universal=u\\r\\n    17. veil-color:               brown=n,orange=o,white=w,yellow=y\\r\\n    18. ring-number:              none=n,one=o,two=t\\r\\n    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\\r\\n    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\\r\\n    21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\\r\\n    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d', 'citation': None}}\n",
      "                        name     role         type demographic  \\\n",
      "0                  poisonous   Target  Categorical        None   \n",
      "1                  cap-shape  Feature  Categorical        None   \n",
      "2                cap-surface  Feature  Categorical        None   \n",
      "3                  cap-color  Feature       Binary        None   \n",
      "4                    bruises  Feature  Categorical        None   \n",
      "5                       odor  Feature  Categorical        None   \n",
      "6            gill-attachment  Feature  Categorical        None   \n",
      "7               gill-spacing  Feature  Categorical        None   \n",
      "8                  gill-size  Feature  Categorical        None   \n",
      "9                 gill-color  Feature  Categorical        None   \n",
      "10               stalk-shape  Feature  Categorical        None   \n",
      "11                stalk-root  Feature  Categorical        None   \n",
      "12  stalk-surface-above-ring  Feature  Categorical        None   \n",
      "13  stalk-surface-below-ring  Feature  Categorical        None   \n",
      "14    stalk-color-above-ring  Feature  Categorical        None   \n",
      "15    stalk-color-below-ring  Feature  Categorical        None   \n",
      "16                 veil-type  Feature       Binary        None   \n",
      "17                veil-color  Feature  Categorical        None   \n",
      "18               ring-number  Feature  Categorical        None   \n",
      "19                 ring-type  Feature  Categorical        None   \n",
      "20         spore-print-color  Feature  Categorical        None   \n",
      "21                population  Feature  Categorical        None   \n",
      "22                   habitat  Feature  Categorical        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                None  None             no  \n",
      "1   bell=b,conical=c,convex=x,flat=f, knobbed=k,su...  None             no  \n",
      "2                fibrous=f,grooves=g,scaly=y,smooth=s  None             no  \n",
      "3   brown=n,buff=b,cinnamon=c,gray=g,green=r, pink...  None             no  \n",
      "4                                      bruises=t,no=f  None             no  \n",
      "5   almond=a,anise=l,creosote=c,fishy=y,foul=f, mu...  None             no  \n",
      "6            attached=a,descending=d,free=f,notched=n  None             no  \n",
      "7                         close=c,crowded=w,distant=d  None             no  \n",
      "8                                    broad=b,narrow=n  None             no  \n",
      "9   black=k,brown=n,buff=b,chocolate=h,gray=g, gre...  None             no  \n",
      "10                             enlarging=e,tapering=t  None             no  \n",
      "11  bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,...  None            yes  \n",
      "12                 fibrous=f,scaly=y,silky=k,smooth=s  None             no  \n",
      "13                 fibrous=f,scaly=y,silky=k,smooth=s  None             no  \n",
      "14  brown=n,buff=b,cinnamon=c,gray=g,orange=o, pin...  None             no  \n",
      "15  brown=n,buff=b,cinnamon=c,gray=g,orange=o, pin...  None             no  \n",
      "16                              partial=p,universal=u  None             no  \n",
      "17                  brown=n,orange=o,white=w,yellow=y  None             no  \n",
      "18                                 none=n,one=o,two=t  None             no  \n",
      "19  cobwebby=c,evanescent=e,flaring=f,large=l, non...  None             no  \n",
      "20  black=k,brown=n,buff=b,chocolate=h,green=r, or...  None             no  \n",
      "21  abundant=a,clustered=c,numerous=n, scattered=s...  None             no  \n",
      "22  grasses=g,leaves=l,meadows=m,paths=p, urban=u,...  None             no  \n"
     ]
    }
   ],
   "source": [
    "df = fetch_dataframe(DATASET_NAME)\n",
    "\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2a0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6498, 22)\n",
      "X_test shape: (1626, 22)\n",
      "y_train shape: (6498, 1)\n",
      "y_test shape: (1626, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.data.features\n",
    "y = df.data.targets\n",
    "\n",
    "X_train, X_test, y_train, y_test = __train_test_split(X, y , test_size=TEST_SIZE, shuffle_and_stratify=True)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "21eac845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __classification_report(y_true, y_pred):\n",
    "    \n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true = y_true.iloc[:, 0]\n",
    "\n",
    "    # Ensure y_true is a Series\n",
    "    if isinstance(y_pred, pd.Series):\n",
    "        y_pred = y_pred.reset_index(drop=True)\n",
    "    elif isinstance(y_pred, list):\n",
    "        y_pred = pd.Series(y_pred)\n",
    "\n",
    "\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"prediction does not have same number of tuples as the true value set\")\n",
    "    \n",
    "    labels = pd.Series(y_true).unique()\n",
    "    \n",
    "    for label in labels:\n",
    "        P = N = TP = FP = TN = FN = 0\n",
    "        \n",
    "        for i in range(len(y_pred)):\n",
    "            true_label = y_true.iloc[i] if hasattr(y_true, 'iloc') else y_true[i]\n",
    "            pred_label = y_pred.iloc[i] if hasattr(y_pred, 'iloc') else y_pred[i]\n",
    "            \n",
    "            if true_label == label:\n",
    "                P += 1\n",
    "            else:\n",
    "                N += 1\n",
    "                \n",
    "            if true_label == label and pred_label == label:\n",
    "                TP += 1\n",
    "            elif true_label == label and pred_label != label:\n",
    "                FN += 1\n",
    "            elif true_label != label and pred_label == label:\n",
    "                FP += 1\n",
    "            elif true_label != label and pred_label != label:\n",
    "                TN += 1\n",
    "        \n",
    "        accuracy = (TP + TN) / (P + N) if (P + N) > 0 else 0.0\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        sensitivity = TP / P if P > 0 else 0.0\n",
    "        specificity = TN / N if N > 0 else 0.0\n",
    "        support = P\n",
    "\n",
    "        print(f\"Label: {label}\")\n",
    "        print(f\"  Accuracy   : {accuracy:.2f}\")\n",
    "        print(f\"  Precision  : {precision:.2f}\")\n",
    "        print(f\"  Recall     : {recall:.2f}\")\n",
    "        print(f\"  F1 Score   : {f1_score:.2f}\")\n",
    "        print(f\"  Sensitivity: {sensitivity:.2f}\")\n",
    "        print(f\"  Specificity: {specificity:.2f}\")\n",
    "        print(f\"  Support    : {support}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "    #overall accuracy\n",
    "    \n",
    "    mathced = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        true_label = y_true.iloc[i] if hasattr(y_true, 'iloc') else y_true[i]\n",
    "        pred_label = y_pred.iloc[i] if hasattr(y_pred, 'iloc') else y_pred[i]\n",
    "        \n",
    "        if true_label == pred_label:\n",
    "            mathced += 1\n",
    "    \n",
    "    overall_accuracy = mathced / len(y_pred) if len(y_pred) > 0 else 0.0\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "48447c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _is_continous(X: pd.Series) -> bool:\n",
    "    return np.issubdtype(X.dtype, np.number) and (len(X.unique()) / len(X) > 0.001)\n",
    "\n",
    "        \n",
    "\n",
    "class DiscreteAttributeSelectionCriteria:\n",
    "    \n",
    "    def __init__(self, value):\n",
    "        self.value = value \n",
    "        \n",
    "    def condition_satisfied(self, val):\n",
    "        if self.value == None:\n",
    "            raise ValueError(f\"value not set\")\n",
    "        \n",
    "        if self.value == val:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        \n",
    "class ContinuousAtrributeSelectionCriteria:\n",
    "    \n",
    "    def __init__(self, start_point, end_point):\n",
    "        self.start_point = start_point\n",
    "        self.end_point = end_point\n",
    "    \n",
    "    def condition_satisfied(self, val):\n",
    "        if self.start_point == None or self.end_point==None:\n",
    "            raise ValueError(f\"value not set\")\n",
    "        \n",
    "        if self.start_point <= val <= self.end_point:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "class DiscreteAndBinaryAtrributeSelectionCriteria:\n",
    "    \n",
    "    def __init__(self, set_of_values):\n",
    "        self.value_set = set_of_values\n",
    "\n",
    "    def condition_satisfied(self, val):\n",
    "        if len(self.value_set) == 0:\n",
    "            raise ValueError(f\"value not set\")\n",
    "        \n",
    "        if val in self.value_set:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "\n",
    "def get_criteria(D,\n",
    "                best_splitting_criterion,\n",
    "                splitting_attr,\n",
    "                multiple_splits_allowed:bool=True\n",
    "                ):\n",
    "    \n",
    "    \n",
    "    if not _is_continous(D[splitting_attr]):\n",
    "        \n",
    "        if multiple_splits_allowed:\n",
    "            return DiscreteAttributeSelectionCriteria(value=best_splitting_criterion.value)\n",
    "        else:\n",
    "            return DiscreteAndBinaryAtrributeSelectionCriteria(set_of_values=best_splitting_criterion.set)\n",
    "    else:\n",
    "        return ContinuousAtrributeSelectionCriteria(start_point=best_splitting_criterion.start_point, \n",
    "                                                    end_point=best_splitting_criterion.end_point)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "f4fecfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2\n",
    "\n",
    "\n",
    "def info(D):\n",
    "    label_counts = D.iloc[:, -1].value_counts().to_dict()\n",
    "    info_val = 0\n",
    "    for label in label_counts:\n",
    "        pi = label_counts[label] / len(D)\n",
    "        info_val += - pi * log2(pi)\n",
    "    return info_val\n",
    "\n",
    "def info_A(D, attr):\n",
    "    info_A = 0\n",
    "    attr_values = D[attr].unique()\n",
    "    for attr_val in attr_values:\n",
    "        Dj = D[D[attr] == attr_val]\n",
    "        info_A += (len(Dj) / len(D)) * info(Dj)\n",
    "    return info_A\n",
    "\n",
    "def Gain(D, A):\n",
    "    return info(D) - info_A(D, A)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "39134172",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from platform import node\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.isLeaf = False\n",
    "        self.split_attribute = None  \n",
    "        self.returning_class = None\n",
    "        self.attribute_selection_criteria = None\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, multiple_splits_allowed=True):\n",
    "        self.root = None\n",
    "        self.multiple_splits_allowed = multiple_splits_allowed\n",
    "\n",
    "    def attribute_selection(self, D, attribute_list):\n",
    "        best_gain = -1\n",
    "        best_attr = None\n",
    "        best_criterion = None\n",
    "\n",
    "        for attr in attribute_list:\n",
    "            \n",
    "            if len(D[attr].unique()) <= 1:\n",
    "                continue\n",
    "\n",
    "            if _is_continous(D[attr]):\n",
    "                sorted_vals = np.sort(D[attr].dropna().unique())\n",
    "                split_points = [(sorted_vals[i] + sorted_vals[i+1]) / 2 for i in range(len(sorted_vals)-1)]\n",
    "\n",
    "                for split in split_points:\n",
    "                    D_left = D[D[attr] <= split]\n",
    "                    D_right = D[D[attr] > split]\n",
    "                    if len(D_left) == 0 or len(D_right) == 0:\n",
    "                        continue\n",
    "                    weighted_info = (len(D_left)/len(D)) * info(D_left) + (len(D_right)/len(D)) * info(D_right)\n",
    "                    gain = info(D) - weighted_info\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_attr = attr\n",
    "                        best_criterion = [split]  # Store best split point\n",
    "            else:\n",
    "                gain = Gain(D, attr)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_attr = attr\n",
    "                    best_criterion = D[attr].unique()\n",
    "\n",
    "        return best_criterion, best_attr\n",
    "\n",
    "    def build_tree(self, X_train, y_train):\n",
    "        # Combine features and labels into one DataFrame\n",
    "        D = pd.concat([X_train, y_train], axis=1)\n",
    "        attribute_list = set(X_train.columns)\n",
    "\n",
    "        def generate_decision_tree(D, attribute_list):\n",
    "            node = Node()\n",
    "\n",
    "            # Stopping condition 1: All samples have the same label\n",
    "            if len(D.iloc[:, -1].unique()) == 1:\n",
    "                node.isLeaf = True\n",
    "                node.returning_class = D.iloc[:, -1].iloc[0]\n",
    "                return node\n",
    "\n",
    "            # Stopping condition 2: No attributes left to split\n",
    "            if len(attribute_list) == 0:\n",
    "                node.isLeaf = True\n",
    "                majority_class = D.iloc[:, -1].value_counts().idxmax()\n",
    "                node.returning_class = majority_class\n",
    "                return node\n",
    "\n",
    "            best_criterion, best_attr = self.attribute_selection(D, attribute_list)\n",
    "            \n",
    "            node.split_attribute = best_attr  # Store the attribute name\n",
    "            \n",
    "            if not self.multiple_splits_allowed:\n",
    "                attribute_list = attribute_list - {best_attr}\n",
    "\n",
    "            # If no attribute gives positive gain, make leaf node with majority class\n",
    "            if best_attr is None or len(best_criterion) == 0:\n",
    "                node.isLeaf = True\n",
    "                node.returning_class = D.iloc[:, -1].value_counts().idxmax()\n",
    "                return node\n",
    "\n",
    "            \n",
    "            if _is_continous(D[best_attr]):\n",
    "                split = best_criterion[0]\n",
    "                \n",
    "                node.attribute_selection_criteria = ContinuousAtrributeSelectionCriteria(start_point=-float('inf'), end_point=split)\n",
    "                \n",
    "                D_left = D[D[best_attr] <= split]\n",
    "                D_right = D[D[best_attr] > split]\n",
    "                \n",
    "                if len(D_left) == 0 or len(D_right) == 0:\n",
    "                    node.isLeaf = True\n",
    "                    node.returning_class = D.iloc[:, -1].value_counts().idxmax()\n",
    "                    return node\n",
    "\n",
    "\n",
    "                node.children['left'] = generate_decision_tree(D_left, attribute_list.copy())\n",
    "                node.children['right'] = generate_decision_tree(D_right, attribute_list.copy())\n",
    "            else:\n",
    "                node.attribute_selection_criteria = DiscreteAttributeSelectionCriteria(value=best_criterion[0])\n",
    "            # If multiple splits are NOT allowed, remove the chosen attribute\n",
    "                \n",
    "\n",
    "                # Split dataset by each attribute value and recurse\n",
    "                for attr_val in best_criterion:\n",
    "                    D_j = D[D[best_attr] == attr_val]\n",
    "\n",
    "                    # If no samples in this subset, create leaf with majority class of parent\n",
    "                    if len(D_j) == 0:\n",
    "                        leaf_node = Node()\n",
    "                        leaf_node.isLeaf = True\n",
    "                        leaf_node.returning_class = D.iloc[:, -1].value_counts().idxmax()\n",
    "                        node.children[attr_val] = leaf_node\n",
    "                    else:\n",
    "                        node.children[attr_val] = generate_decision_tree(D_j, attribute_list.copy())\n",
    "\n",
    "            return node\n",
    "\n",
    "        self.root = generate_decision_tree(D, attribute_list)\n",
    "\n",
    "    def _majority_class(self, node):\n",
    "        from collections import Counter\n",
    "\n",
    "        def collect_leaf_classes(n):\n",
    "            if n.isLeaf:\n",
    "                return [n.returning_class]\n",
    "            labels = []\n",
    "            for child in n.children.values():\n",
    "                labels.extend(collect_leaf_classes(child))\n",
    "            return labels\n",
    "\n",
    "        leaf_classes = collect_leaf_classes(node)\n",
    "        if not leaf_classes:\n",
    "            return None\n",
    "        return Counter(leaf_classes).most_common(1)[0][0]\n",
    "\n",
    "    def predict_single(self, x):\n",
    "        node = self.root\n",
    "        while not node.isLeaf:\n",
    "            attr = node.split_attribute  # <--- Get column name\n",
    "            val = x[attr]                # <--- Safe: x[attr] is now x[\"age\"] or similar\n",
    "\n",
    "            if isinstance(node.attribute_selection_criteria, ContinuousAtrributeSelectionCriteria):\n",
    "                if node.attribute_selection_criteria.condition_satisfied(val):\n",
    "                    node = node.children['left']\n",
    "                else:\n",
    "                    node = node.children['right']\n",
    "            elif isinstance(node.attribute_selection_criteria, DiscreteAttributeSelectionCriteria):\n",
    "                if node.attribute_selection_criteria.condition_satisfied(val):\n",
    "                    node = node.children[val]\n",
    "                else:\n",
    "                    return self._majority_class(node)\n",
    "\n",
    "        return node.returning_class\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self.predict_single(row) for _, row in X_test.iterrows()]\n",
    "        return pd.Series(predictions, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "6f29cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.build_tree(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "57e6c36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for prediction: {'cap-shape': 'f', 'cap-surface': 's', 'cap-color': 'e', 'bruises': 'f', 'odor': 'y', 'gill-attachment': 'f', 'gill-spacing': 'c', 'gill-size': 'n', 'gill-color': 'b', 'stalk-shape': 't', 'stalk-root': nan, 'stalk-surface-above-ring': 'k', 'stalk-surface-below-ring': 'k', 'stalk-color-above-ring': 'p', 'stalk-color-below-ring': 'w', 'veil-type': 'p', 'veil-color': 'w', 'ring-number': 'o', 'ring-type': 'e', 'spore-print-color': 'w', 'population': 'v', 'habitat': 'l'}\n",
      "Predicted class: p -- expected: p)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example prediction\n",
    "example = X_test.iloc[0]\n",
    "print(f\"Example for prediction: {example.to_dict()}\")\n",
    "predicted_class = model.predict_single(example)\n",
    "print(f\"Predicted class: {predicted_class} -- expected: {y_test.iloc[0, 0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "cb0e8315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test type: <class 'pandas.core.frame.DataFrame'>\n",
      "y_test shape: (1626, 1)\n",
      "y_preds type: <class 'pandas.core.series.Series'>\n",
      "y_preds shape: (1626,)\n",
      "DATASET_NAME = mushroom\n",
      "Label: p\n",
      "  Accuracy   : 0.48\n",
      "  Precision  : 0.48\n",
      "  Recall     : 1.00\n",
      "  F1 Score   : 0.65\n",
      "  Sensitivity: 1.00\n",
      "  Specificity: 0.00\n",
      "  Support    : 784\n",
      "------------------------------\n",
      "Label: e\n",
      "  Accuracy   : 0.48\n",
      "  Precision  : 0.00\n",
      "  Recall     : 0.00\n",
      "  F1 Score   : 0.00\n",
      "  Sensitivity: 0.00\n",
      "  Specificity: 1.00\n",
      "  Support    : 842\n",
      "------------------------------\n",
      "Overall Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test)\n",
    "\n",
    "print(\"y_test type:\", type(y_test))\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_preds type:\", type(y_preds))\n",
    "print(\"y_preds shape:\", y_preds.shape)\n",
    "\n",
    "if len(y_test) != len(y_preds):\n",
    "    raise ValueError(\"y_test and y_preds must have the same length.\")\n",
    "# Evaluate the model\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_preds)}\")\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_preds))\n",
    "\n",
    "\n",
    "print(f\"DATASET_NAME = {DATASET_NAME}\")\n",
    "__classification_report(y_test, y_preds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
