{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f749d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "463094a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from file where:\n",
    "    - -1 separates events\n",
    "    - -2 separates sequences\n",
    "    - Other numbers are event IDs\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    current_sequence = []\n",
    "    current_event = set()\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            for token in tokens:\n",
    "                try:\n",
    "                    num = int(token)\n",
    "                    if num == -2:  # End of sequence\n",
    "                        if current_event:\n",
    "                            current_sequence.append(sorted(current_event))\n",
    "                            current_event = set()\n",
    "                        if current_sequence:\n",
    "                            sequences.append(current_sequence)\n",
    "                            current_sequence = []\n",
    "                    elif num == -1:  # End of event\n",
    "                        if current_event:\n",
    "                            current_sequence.append(sorted(current_event))\n",
    "                            current_event = set()\n",
    "                    else:  # Event ID\n",
    "                        current_event.add(num)\n",
    "                except ValueError:\n",
    "                    # Skip non-integer tokens\n",
    "                    continue\n",
    "            \n",
    "            # Handle end of line (treat as end of sequence)\n",
    "            if current_event:\n",
    "                current_sequence.append(sorted(current_event))\n",
    "                current_event = set()\n",
    "            if current_sequence:\n",
    "                sequences.append(current_sequence)\n",
    "                current_sequence = []\n",
    "    \n",
    "    return sequences\n",
    "\n",
    "def is_subsequence(main_sequence, subsequence):\n",
    "    \"\"\"Check if subsequence is contained in main_sequence\"\"\"\n",
    "    def is_subsequence_recursive(subsequence_clone, start=0):\n",
    "        if not subsequence_clone:\n",
    "            return True\n",
    "        first_elem = set(subsequence_clone.pop(0))\n",
    "        for i in range(start, len(main_sequence)):\n",
    "            if set(main_sequence[i]).issuperset(first_elem):\n",
    "                return is_subsequence_recursive(subsequence_clone, i + 1)\n",
    "        return False\n",
    "    return is_subsequence_recursive(copy.deepcopy(subsequence))\n",
    "\n",
    "def sequence_length(sequence):\n",
    "    \"\"\"Calculate the total number of items in the sequence\"\"\"\n",
    "    return sum(len(i) for i in sequence)\n",
    "\n",
    "def count_support(file_path, cand_seq):\n",
    "    \"\"\"Count how many sequences contain the candidate sequence\"\"\"\n",
    "    sequences = load_data(file_path)\n",
    "    return sum(1 for seq in sequences if is_subsequence(seq, cand_seq))\n",
    "\n",
    "def gen_cands_for_pair(cand1, cand2):\n",
    "    \"\"\"Generate a new candidate from two candidates of length k-1\"\"\"\n",
    "    cand1_clone = copy.deepcopy(cand1)\n",
    "    cand2_clone = copy.deepcopy(cand2)\n",
    "    \n",
    "    if len(cand1[0]) == 1:\n",
    "        cand1_clone.pop(0)\n",
    "    else:\n",
    "        cand1_clone[0] = cand1_clone[0][1:]\n",
    "        \n",
    "    if len(cand2[-1]) == 1:\n",
    "        cand2_clone.pop(-1)\n",
    "    else:\n",
    "        cand2_clone[-1] = cand2_clone[-1][:-1]\n",
    "        \n",
    "    if not cand1_clone == cand2_clone:\n",
    "        return []\n",
    "    else:\n",
    "        new_cand = copy.deepcopy(cand1)\n",
    "        if len(cand2[-1]) == 1:\n",
    "            new_cand.append(cand2[-1])\n",
    "        else:\n",
    "            new_cand[-1].extend([cand2[-1][-1]])\n",
    "        return new_cand\n",
    "\n",
    "def gen_cands(last_lvl_cands):\n",
    "    \"\"\"Generate candidate sequences of length k+1 from frequent sequences of length k\"\"\"\n",
    "    k = sequence_length(last_lvl_cands[0]) + 1\n",
    "    \n",
    "    if k == 2:\n",
    "        flat_short_cands = [item for sublist2 in last_lvl_cands \n",
    "                          for sublist1 in sublist2 \n",
    "                          for item in sublist1]\n",
    "        result = [[[a, b]] for a in flat_short_cands \n",
    "                          for b in flat_short_cands \n",
    "                          if b > a]\n",
    "        result.extend([[[a], [b]] for a in flat_short_cands \n",
    "                                     for b in flat_short_cands])\n",
    "        return result\n",
    "    else:\n",
    "        cands = []\n",
    "        for i in range(len(last_lvl_cands)):\n",
    "            for j in range(len(last_lvl_cands)):\n",
    "                new_cand = gen_cands_for_pair(last_lvl_cands[i], last_lvl_cands[j])\n",
    "                if new_cand:\n",
    "                    cands.append(new_cand)\n",
    "        cands.sort()\n",
    "        return cands\n",
    "\n",
    "def gen_direct_subsequences(sequence):\n",
    "    \"\"\"Generate all possible direct subsequences of length k-1\"\"\"\n",
    "    result = []\n",
    "    for i, itemset in enumerate(sequence):\n",
    "        if len(itemset) == 1:\n",
    "            seq_clone = copy.deepcopy(sequence)\n",
    "            seq_clone.pop(i)\n",
    "            result.append(seq_clone)\n",
    "        else:\n",
    "            for j in range(len(itemset)):\n",
    "                seq_clone = copy.deepcopy(sequence)\n",
    "                seq_clone[i].pop(j)\n",
    "                result.append(seq_clone)\n",
    "    return result\n",
    "\n",
    "def prune_cands(last_lvl_cands, cands_gen):\n",
    "    \"\"\"Prune candidates that have any (k-1)-subsequence that is not frequent\"\"\"\n",
    "    return [cand for cand in cands_gen \n",
    "            if all(any(cand_subseq == freq_seq for freq_seq in last_lvl_cands) \n",
    "                 for cand_subseq in gen_direct_subsequences(cand))]\n",
    "\n",
    "def gsp(dataset, file_path, min_sup, verbose=False):\n",
    "    \"\"\"\n",
    "    GSP (Generalized Sequential Pattern) algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: List of sequences (each sequence is a list of itemsets)\n",
    "    - min_sup: Minimum support (fraction or absolute count)\n",
    "    - verbose: Print progress if True\n",
    "    \n",
    "    Returns:\n",
    "    - List of (sequence, support) tuples, sorted by support (descending)\n",
    "    \"\"\"\n",
    "    # Convert min_sup to absolute count if it's a fraction\n",
    "    if 0 < min_sup < 1:\n",
    "        min_sup = int(min_sup * len(dataset))\n",
    "    \n",
    "    # Initialize\n",
    "    overall = []\n",
    "    \n",
    "    # Get all unique items\n",
    "    items = sorted(set([item for sequence in dataset\n",
    "                       for itemset in sequence\n",
    "                       for item in itemset]))\n",
    "    \n",
    "    total_cands_generated = 0\n",
    "    # Generate 1-sequences\n",
    "    single_item_sequences = [[[item]] for item in items]\n",
    "    total_cands_generated += len(single_item_sequences)\n",
    "    single_item_counts = [(s, count_support(file_path, s)) \n",
    "                         for s in single_item_sequences]\n",
    "    single_item_counts = [(i, count) for i, count in single_item_counts \n",
    "                         if count >= min_sup]\n",
    "    \n",
    "    print(f\"k : {1}\")\n",
    "    for item, count in single_item_counts:\n",
    "        print(f\"Sequence: {item}, Support: {count}\")\n",
    "    \n",
    "    overall.append(single_item_counts)\n",
    "    \n",
    "    # Generate k-sequences for k > 1\n",
    "    k = 1\n",
    "    while overall[k - 1]:\n",
    "        print(f\"k : {k+1}\")\n",
    "        last_lvl_cands = [x[0] for x in overall[k - 1]]\n",
    "        cands_gen = gen_cands(last_lvl_cands)\n",
    "        cands_pruned = prune_cands(last_lvl_cands, cands_gen)\n",
    "        cands_counts = [(s, count_support(file_path, s)) for s in cands_pruned]\n",
    "        print(f\"Candidates generated, lvl {k + 1}: {len(cands_gen)}\")\n",
    "        total_cands_generated += len(cands_gen)\n",
    "        \n",
    "        for i, count in cands_counts:\n",
    "            print(f\"Candidate: {i}, Count: {count}\")\n",
    "        \n",
    "        \n",
    "        result_lvl = [(i, count) for i, count in cands_counts if count >= min_sup]\n",
    "        \n",
    "        # if verbose > 1:\n",
    "        #     print('Candidates generated, lvl', k + 1, ':', cands_gen)\n",
    "        #     print('\\nCandidates pruned, lvl', k + 1, ':', cands_pruned)\n",
    "        #     print('Result, Level', k + 1, ':', result_lvl)\n",
    "        #     print('-' * 100)\n",
    "        \n",
    "        \n",
    "        print(f\"Result, Level {k + 1}: {len(result_lvl)} sequences found\")\n",
    "        \n",
    "        for item, count in result_lvl:\n",
    "            print(f\"Sequence: {item}, Support: {count}\")\n",
    "            \n",
    "        overall.append(result_lvl)\n",
    "        k += 1\n",
    "    \n",
    "    # Flatten the results and sort by support (descending)\n",
    "    overall = overall[:-1]  # Remove empty last level\n",
    "    overall = [item for sublist in overall for item in sublist]\n",
    "    overall.sort(key=lambda tup: (tup[1], -sequence_length(tup[0])), reverse=True)\n",
    "    \n",
    "    print(f\"Total candidates generated: {total_cands_generated}\")\n",
    "    \n",
    "    return overall\n",
    "\n",
    "def format_sequence(sequence):\n",
    "    \"\"\"Format a sequence for display\"\"\"\n",
    "    return str(sequence).replace('], [', ' -> ').replace('[', '').replace(']', '')\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16b64118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import time, math\n",
    "\n",
    "\n",
    "def main_caller(file_name, min_sup_list):\n",
    "    DATASET_DIR = \"/home/faiak/Desktop/Academic/Data-Mining/Assignment_4/Datasets/\"\n",
    "    file_path = DATASET_DIR + file_name\n",
    "    sequences = load_data(file_path)\n",
    "    print(f\"Loaded {len(sequences)} sequences from file\")\n",
    "    print(\"loaded file : \", file_name)\n",
    "    \n",
    "    for min_sup in min_sup_list:\n",
    "        main(sequences, file_path, min_sup)\n",
    "    print(\"All computations completed.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def main(sequences, file_path, min_sup):\n",
    "    \n",
    "    if 0<=min_sup<=1:\n",
    "        min_sup = math.ceil(min_sup * len(sequences))\n",
    "\n",
    "    print(f\"Running GSP with min_sup={min_sup}\")\n",
    "    \n",
    "    start_time = time.perf_counter_ns()\n",
    "    tracemalloc.start()\n",
    "    \n",
    "    results = gsp(sequences, file_path, min_sup, verbose=True)\n",
    "    \n",
    "    end_time = time.perf_counter_ns()\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    tracemalloc.stop()\n",
    "    \n",
    "    elapsed_time = (end_time - start_time) / 1e6  # Convert to milliseconds\n",
    "    print(f\"Execution time: {elapsed_time:.2f} ms\")\n",
    "    \n",
    "    print(f\"Memory usage: {current / 1024:.2f} KB, Peak: {peak / 1024:.2f} KB\")\n",
    "    \n",
    "    # Print results\n",
    "    # print(\"\\nFrequent sequences:\")\n",
    "    # for i, (seq, support) in enumerate(results[:54], 1):\n",
    "    #     print(f\"{i}. {format_sequence(seq)} (Support: {support})\")\n",
    "    \n",
    "    print(f\"\\nTotal frequent sequences found: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72b726e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 sequences from file\n",
      "loaded file :  new.txt\n",
      "Running GSP with min_sup=3\n",
      "k : 1\n",
      "Sequence: [[1]], Support: 3\n",
      "Sequence: [[2]], Support: 5\n",
      "Sequence: [[3]], Support: 4\n",
      "Sequence: [[4]], Support: 5\n",
      "Sequence: [[5]], Support: 4\n",
      "Sequence: [[6]], Support: 4\n",
      "k : 2\n",
      "Candidates generated, lvl 2: 51\n",
      "Candidate: [[1, 2]], Count: 3\n",
      "Candidate: [[1, 3]], Count: 2\n",
      "Candidate: [[1, 4]], Count: 1\n",
      "Candidate: [[1, 5]], Count: 1\n",
      "Candidate: [[1, 6]], Count: 0\n",
      "Candidate: [[2, 3]], Count: 2\n",
      "Candidate: [[2, 4]], Count: 4\n",
      "Candidate: [[2, 5]], Count: 2\n",
      "Candidate: [[2, 6]], Count: 1\n",
      "Candidate: [[3, 4]], Count: 2\n",
      "Candidate: [[3, 5]], Count: 1\n",
      "Candidate: [[3, 6]], Count: 0\n",
      "Candidate: [[4, 5]], Count: 2\n",
      "Candidate: [[4, 6]], Count: 3\n",
      "Candidate: [[5, 6]], Count: 2\n",
      "Candidate: [[1], [1]], Count: 2\n",
      "Candidate: [[1], [2]], Count: 3\n",
      "Candidate: [[1], [3]], Count: 2\n",
      "Candidate: [[1], [4]], Count: 2\n",
      "Candidate: [[1], [5]], Count: 0\n",
      "Candidate: [[1], [6]], Count: 1\n",
      "Candidate: [[2], [1]], Count: 2\n",
      "Candidate: [[2], [2]], Count: 3\n",
      "Candidate: [[2], [3]], Count: 2\n",
      "Candidate: [[2], [4]], Count: 2\n",
      "Candidate: [[2], [5]], Count: 0\n",
      "Candidate: [[2], [6]], Count: 1\n",
      "Candidate: [[3], [1]], Count: 2\n",
      "Candidate: [[3], [2]], Count: 3\n",
      "Candidate: [[3], [3]], Count: 2\n",
      "Candidate: [[3], [4]], Count: 3\n",
      "Candidate: [[3], [5]], Count: 2\n",
      "Candidate: [[3], [6]], Count: 2\n",
      "Candidate: [[4], [1]], Count: 0\n",
      "Candidate: [[4], [2]], Count: 1\n",
      "Candidate: [[4], [3]], Count: 1\n",
      "Candidate: [[4], [4]], Count: 3\n",
      "Candidate: [[4], [5]], Count: 1\n",
      "Candidate: [[4], [6]], Count: 1\n",
      "Candidate: [[5], [1]], Count: 0\n",
      "Candidate: [[5], [2]], Count: 3\n",
      "Candidate: [[5], [3]], Count: 0\n",
      "Candidate: [[5], [4]], Count: 3\n",
      "Candidate: [[5], [5]], Count: 2\n",
      "Candidate: [[5], [6]], Count: 3\n",
      "Candidate: [[6], [1]], Count: 0\n",
      "Candidate: [[6], [2]], Count: 3\n",
      "Candidate: [[6], [3]], Count: 0\n",
      "Candidate: [[6], [4]], Count: 3\n",
      "Candidate: [[6], [5]], Count: 2\n",
      "Candidate: [[6], [6]], Count: 1\n",
      "Result, Level 2: 13 sequences found\n",
      "Sequence: [[1, 2]], Support: 3\n",
      "Sequence: [[2, 4]], Support: 4\n",
      "Sequence: [[4, 6]], Support: 3\n",
      "Sequence: [[1], [2]], Support: 3\n",
      "Sequence: [[2], [2]], Support: 3\n",
      "Sequence: [[3], [2]], Support: 3\n",
      "Sequence: [[3], [4]], Support: 3\n",
      "Sequence: [[4], [4]], Support: 3\n",
      "Sequence: [[5], [2]], Support: 3\n",
      "Sequence: [[5], [4]], Support: 3\n",
      "Sequence: [[5], [6]], Support: 3\n",
      "Sequence: [[6], [2]], Support: 3\n",
      "Sequence: [[6], [4]], Support: 3\n",
      "k : 3\n",
      "Candidates generated, lvl 3: 26\n",
      "Candidate: [[1], [2], [2]], Count: 0\n",
      "Candidate: [[1, 2], [2]], Count: 3\n",
      "Candidate: [[2], [2], [2]], Count: 0\n",
      "Candidate: [[3], [2], [2]], Count: 0\n",
      "Candidate: [[3], [2, 4]], Count: 2\n",
      "Candidate: [[3], [4], [4]], Count: 2\n",
      "Candidate: [[4], [4], [4]], Count: 1\n",
      "Candidate: [[4, 6], [4]], Count: 1\n",
      "Candidate: [[5], [2], [2]], Count: 0\n",
      "Candidate: [[5], [2, 4]], Count: 3\n",
      "Candidate: [[5], [4], [4]], Count: 1\n",
      "Candidate: [[5], [4, 6]], Count: 2\n",
      "Candidate: [[5], [6], [2]], Count: 3\n",
      "Candidate: [[5], [6], [4]], Count: 3\n",
      "Candidate: [[6], [2], [2]], Count: 0\n",
      "Candidate: [[6], [2, 4]], Count: 3\n",
      "Candidate: [[6], [4], [4]], Count: 0\n",
      "Result, Level 3: 5 sequences found\n",
      "Sequence: [[1, 2], [2]], Support: 3\n",
      "Sequence: [[5], [2, 4]], Support: 3\n",
      "Sequence: [[5], [6], [2]], Support: 3\n",
      "Sequence: [[5], [6], [4]], Support: 3\n",
      "Sequence: [[6], [2, 4]], Support: 3\n",
      "k : 4\n",
      "Candidates generated, lvl 4: 1\n",
      "Candidate: [[5], [6], [2, 4]], Count: 3\n",
      "Result, Level 4: 1 sequences found\n",
      "Sequence: [[5], [6], [2, 4]], Support: 3\n",
      "k : 5\n",
      "Candidates generated, lvl 5: 0\n",
      "Result, Level 5: 0 sequences found\n",
      "Total candidates generated: 84\n",
      "Execution time: 62.83 ms\n",
      "Memory usage: 55.76 KB, Peak: 94.95 KB\n",
      "\n",
      "Total frequent sequences found: 25\n",
      "All computations completed.\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    # \"bike.txt\": [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "    # \"eshop.txt\": [0.4, 0.45, 0.5, 0.55, 0.6, 0.8],\n",
    "    # \"sign.txt\" : [0.2,0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    # \"book.txt\": [0.5],\n",
    "    # \"BmsWeb1.txt\": [0.1],\n",
    "    # \"bike.txt\": [0.2],\n",
    "    \"new.txt\" : [0.4]\n",
    "}\n",
    "\n",
    "\n",
    "for file_name, min_sup_list in datasets.items():\n",
    "    main_caller(file_name, min_sup_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
